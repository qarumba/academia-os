ACADEMIAOS 2.0 - PRODUCT DOCUMENTATION

1. PRODUCT OVERVIEW

AcademiaOS 2.0 is a React/TypeScript application for academic information retrieval and automated qualitative research. This enhanced fork of Thomas Üllebecker's AcademiaOS provides AI-powered tools for literature analysis, theory development, and qualitative coding using the Gioia methodology.

Version 2.0 Enhancements:
- Multi-provider AI model support (OpenAI, Anthropic Claude)
- Complete LangChain v0.3.27 migration with modern architecture
- Self-hosted LangFuse AI Observatory for academic data privacy
- Enhanced user interface with progressive loading states
- Native Anthropic support with automatic fallback handling
- Complete Gioia methodology automation with improved reliability

Academic Foundation:
Based on Thomas Üllebecker's research: "AcademiaOS: Automating Grounded Theory Development in Qualitative Research with Large Language Models" (arXiv:2403.08844)

2. TARGET AUDIENCE

Primary Users:
- Academic researchers conducting qualitative studies
- Graduate students working on dissertations
- Research teams analyzing large datasets
- Social scientists using grounded theory methodologies
- Institutions seeking to enhance research capabilities

Key Use Cases:
- Literature reviews and paper analysis
- Qualitative data coding (interviews, transcripts, documents)
- Theory construction and validation
- Academic paper information extraction
- Multi-document thematic analysis
- Research methodology education and training

3. TECHNICAL ARCHITECTURE

Frontend Stack:
- React 18.2.0 with TypeScript 4.9.5
- Ant Design 5.9.0 (UI components)
- Redux 4.2.1 (state management)
- Mermaid 10.4.0 (visualization)
- PDF.js 3.10.111 (document processing)

Backend Services:
- Node.js server for LangFuse and Semantic Scholar API proxies
- Express.js for API endpoints

AI Integration:
- LangChain v0.3.27 (fully migrated from legacy v0.0.190)
- @langchain/core 0.3.57, @langchain/openai 0.5.12, @langchain/anthropic 0.3.21
- @langchain/textsplitters 0.1.0, @langchain/community 0.3.45
- Native Anthropic integration (@anthropic-ai/sdk 0.39.0)
- Multi-provider abstraction with graceful fallbacks

External APIs:
- Semantic Scholar API (academic paper search)
- LangFuse (self-hosted AI observability)
- Adobe PDF Extract API (OCR processing)

Architecture Patterns:
- Model Configuration System with ModelConfigurationGuard
- Redux state management for configuration persistence
- Service Layer Pattern for business logic separation
- Workflow-based UI with step components

4. CORE FEATURES

Academic Literature Management:
- Semantic Scholar corpus integration
- Automated paper search and ranking
- PDF upload and text extraction
- Custom column extraction for metadata

Qualitative Analysis Workflow:
- Complete Gioia methodology automation
- First-order coding (initial themes)
- Second-order coding (theme aggregation)
- Aggregate dimensions (theoretical constructs)
- Theory construction and model development
- Interactive theory visualization
- Human-in-the-loop critique and iteration

AI Model Configuration:
- Unified interface for OpenAI and Anthropic models
- Automatic fallback handling
- OpenAI embeddings support for all providers
- API key management with validation

AI Observatory and Analytics:
- Self-hosted LangFuse integration for academic data privacy
- Real-time AI model cost tracking and usage metrics
- Academic session monitoring with institutional compliance
- LangChain callback integration for automatic tracing

5. DEVELOPMENT COMMANDS

Local Development:
- npm start: Development server (http://localhost:3000)
- npm test: Test runner in interactive watch mode
- npm run build: Production bundle
- npm install: Install dependencies

Docker Development (Recommended):
- docker-compose up -d: Start React client and API server containers
- docker-compose -f docker-compose.langfuse.yml up -d: Start LangFuse AI Observatory
- aos-full-up: Start all three services (client + server + LangFuse)
- Health checks: localhost:3000, localhost:3001/health, localhost:3030

Alternative Local Development:
- npm run setup: Install all dependencies (client + server)
- npm start: Start React development server
- cd server && npm start: Start Semantic Scholar API proxy server

6. DEPLOYMENT

Build Process:
- npm run build creates optimized production bundle
- Minified React bundle with hash-based filenames
- Multi-container Docker deployment with separate client and server containers
- LangFuse Observatory with PostgreSQL and ClickHouse backends

Requirements:
- Docker and Docker Compose (recommended deployment)
- Node.js 18 LTS (for local development)
- OpenAI API key (required for embeddings) - updated to SDK v5.1.1
- Optional: Anthropic API key (updated to SDK v0.53.0), self-hosted LangFuse instance, Adobe PDF Extract API credentials

Container Architecture:
- academia-os-client: React development server (port 3000)
- academia-os-server: API proxy server (port 3001)  
- langfuse-server: AI monitoring server (port 3030)
- langfuse-db: PostgreSQL database
- langfuse-clickhouse: ClickHouse analytics database

7. LICENSING

License: MIT License (2023 Thomas Übellacker)
- Commercial use permitted
- Modification and distribution permitted
- Include copyright notice in distributions

Attribution:
- Original work by Thomas Üllebecker
- AcademiaOS 2.0 enhancements by A Helme and Claude 4 Sonnet
- Commercial services under academia-os.org domain reserved for Thomas Üllebecker

8. COMMUNITY RESOURCES

Repository: https://github.com/qarumba/academia-os
Original Project: https://github.com/thomasuebi/academia-os
Live Demo (v1.0): https://academia-os.org
Slack Community: https://join.slack.com/t/academiaos/shared_invite/zt-23730lsp0-Qlkv_0Bs3hgMY2FGTC~HnQ

Last Updated: June 8, 2025
Version: 2.0
LangChain Migration: v0.3.27 Complete